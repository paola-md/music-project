{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca3a921-a7d1-47cc-8099-7eee72f0e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append(\"jukebox_clone\")\n",
    "# sys.path.append(\"lucent_clone\")\n",
    "import jukebox\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import scipy\n",
    "import os\n",
    "import numpy as np\n",
    "import nussl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
    "from jukebox.hparams import Hyperparams, setup_hparams\n",
    "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
    "from jukebox.utils.torch_utils import empty_cache\n",
    "from jukebox.utils.jukebox_utils import get_forward_calls_encoder, split_model\n",
    "rank, local_rank, device = setup_dist_from_mpi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed067c40-4f87-4179-81d1-3d7130e77713",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from azure\n",
      "Running  wget -O /home/pajouheshgar/.cache/jukebox/models/5b/vqvae.pth.tar https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-06-04 12:52:18--  https://openaipublic.azureedge.net/jukebox/models/5b/vqvae.pth.tar\n",
      "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.60, 13.107.213.60, 2620:1ec:bdf::60, ...\n",
      "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.60|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7726329 (7.4M) [application/x-tar]\n",
      "Saving to: ‘/home/pajouheshgar/.cache/jukebox/models/5b/vqvae.pth.tar’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 14.5M 1s\n",
      "    50K .......... .......... .......... .......... ..........  1% 7.75M 1s\n",
      "   100K .......... .......... .......... .......... ..........  1% 8.05M 1s\n",
      "   150K .......... .......... .......... .......... ..........  2%  225M 1s\n",
      "   200K .......... .......... .......... .......... ..........  3% 16.0M 1s\n",
      "   250K .......... .......... .......... .......... ..........  3% 3.47M 1s\n",
      "   300K .......... .......... .......... .......... ..........  4%  272M 1s\n",
      "   350K .......... .......... .......... .......... ..........  5% 2.85M 1s\n",
      "   400K .......... .......... .......... .......... ..........  5%  154M 1s\n",
      "   450K .......... .......... .......... .......... ..........  6%  150M 1s\n",
      "   500K .......... .......... .......... .......... ..........  7% 65.8M 1s\n",
      "   550K .......... .......... .......... .......... ..........  7% 28.4M 1s\n",
      "   600K .......... .......... .......... .......... ..........  8% 3.38M 1s\n",
      "   650K .......... .......... .......... .......... ..........  9%  142M 1s\n",
      "   700K .......... .......... .......... .......... ..........  9%  135M 1s\n",
      "   750K .......... .......... .......... .......... .......... 10% 3.30M 1s\n",
      "   800K .......... .......... .......... .......... .......... 11%  273M 1s\n",
      "   850K .......... .......... .......... .......... .......... 11% 44.0M 1s\n",
      "   900K .......... .......... .......... .......... .......... 12%  226M 1s\n",
      "   950K .......... .......... .......... .......... .......... 13%  264M 1s\n",
      "  1000K .......... .......... .......... .......... .......... 13% 2.68M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 14%  272M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 15%  283M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 15% 48.4M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 16%  300M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 17% 3.31M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 17%  140M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 18%  126M 1s\n",
      "  1400K .......... .......... .......... .......... .......... 19% 25.6M 1s\n",
      "  1450K .......... .......... .......... .......... .......... 19%  295M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 20% 3.54M 1s\n",
      "  1550K .......... .......... .......... .......... .......... 21%  217M 1s\n",
      "  1600K .......... .......... .......... .......... .......... 21%  285M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 22% 1.69M 1s\n",
      "  1700K .......... .......... .......... .......... .......... 23%  268M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 23% 52.3M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 24%  275M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 25%  297M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 25% 52.6M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 26%  246M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 27% 25.4M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 27%  274M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 28%  161M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 29% 11.2M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 29%  272M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 30%  268M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 31% 3.78M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 31%  226M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 32% 15.6M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 33%  274M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 33%  265M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 34% 3.67M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 35%  146M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 35% 15.3M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 36%  266M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 37%  233M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 37% 3.71M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 38%  278M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 39% 14.7M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 39%  234M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 40%  284M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 41% 3.71M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 41%  143M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 42% 15.4M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 43%  145M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 43%  265M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 44% 3.69M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 45%  248M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 45%  285M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 46% 6.57M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 47%  136M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 47% 5.78M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 48%  269M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 49%  284M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 49% 6.08M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 50%  253M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 51% 5.78M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 51%  144M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 52%  145M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 53% 6.67M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 53%  291M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 54% 5.66M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 55%  229M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 55%  936K 0s\n",
      "  4200K .......... .......... .......... .......... .......... 56%  256M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 56%  278M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 57%  277M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 58%  213M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 58%  238M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 59%  250M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 60%  279M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 60%  136M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 61%  154M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 62%  146M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 62%  143M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 63%  126M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 64%  140M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 64%  133M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 65%  142M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 66% 15.7M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 66%  193M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 67%  272M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 68% 6.29M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 68%  125M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 69% 6.08M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 70%  204M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 70%  291M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 71% 5.94M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 72%  171M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 72%  206M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 73% 2.24M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 74%  145M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 74% 92.4M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 75%  145M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 76%  136M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 76% 3.05M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 77%  142M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 78% 48.4M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 78%  183M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 79%  229M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 80% 3.21M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 80%  281M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 81% 39.0M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 82%  212M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 82%  290M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 83% 3.15M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 84%  277M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 84% 34.7M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 85%  227M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 86%  283M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 86% 3.29M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 87%  243M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 88%  280M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 88% 15.0M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 89%  135M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 90% 3.64M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 90%  147M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 91%  144M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 92% 2.85M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 92%  238M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 93% 78.5M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 94%  200M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 94%  289M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 95% 3.16M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 96%  278M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 96% 35.2M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 97%  247M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 98%  264M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 98% 46.1M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 99%  289M 0s\n",
      "  7500K .......... .......... .......... .......... .....     100%  262M=0.5s\n",
      "\n",
      "2022-06-04 12:52:19 (13.7 MB/s) - ‘/home/pajouheshgar/.cache/jukebox/models/5b/vqvae.pth.tar’ saved [7726329/7726329]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored from /home/pajouheshgar/.cache/jukebox/models/5b/vqvae.pth.tar\n",
      "0: Loading vqvae in eval mode\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = \"5b\" # or \"1b_lyrics\"     \n",
    "vqvae, *priors = MODELS[model]\n",
    "hparams = setup_hparams(vqvae, dict(sample_length = 1048576))\n",
    "vqvae = make_vqvae(hparams, device)\n",
    "vqvae = vqvae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c910d3-cf92-4232-8da3-3d15bff0605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seconds = 2\n",
    "sample_rate = 44100\n",
    "t = np.linspace(0, num_seconds, sample_rate * num_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d9593ed3-98e8-4d84-9182-670ae4778713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose the level of JukeBox and hook it\n",
    "from lucent.optvis.render import hook_model\n",
    "from functools import partial\n",
    "from jukebox.utils.jukebox_utils import get_forward_calls_encoder, get_forward_calls_decoder, split_model, compose_funclist\n",
    "\n",
    "# Functions to play and save audio\n",
    "from jukebox.utils.jukebox_utils import compose_funclist\n",
    "play = compose_funclist([\n",
    "    lambda x: x.detach().cpu().numpy()[0,0],\n",
    "    # lambda x: (x - x.min()) / (x.max() - x.min()),\n",
    "    # lambda x: np.clip(x, -1.0, 1.0),\n",
    "    lambda x: x / max(x.max(), -x.min()),\n",
    "    lambda x: nussl.AudioSignal(audio_data_array=x, sample_rate=44100),\n",
    "    lambda x: (x, x.embed_audio())\n",
    "])\n",
    "\n",
    "save = compose_funclist([\n",
    "    lambda x: x.detach().cpu().numpy()[0,0],\n",
    "    # lambda x: (x - x.min()) / (x.max() - x.min()),\n",
    "    # lambda x: np.clip(x, -1.0, 1.0),\n",
    "    lambda x: x / max(x.max(), -x.min()),\n",
    "    lambda x: nussl.AudioSignal(audio_data_array=x, sample_rate=44100),\n",
    "    lambda x: x\n",
    "])\n",
    "\n",
    "post_process = compose_funclist([\n",
    "    lambda x: x.detach().cpu().numpy()[0,0],\n",
    "    lambda x: x / max(x.max(), -x.min()),\n",
    "])\n",
    "\n",
    "\n",
    "level = 2\n",
    "encoder = vqvae.encoders[level]\n",
    "bottleneck = vqvae.bottleneck.level_blocks[level]\n",
    "decoder = vqvae.decoders[level]\n",
    "\n",
    "encoder_hook, encoder_layers = hook_model(encoder, include_class_name=False)\n",
    "encoder_calls, encoder_layer_names = get_forward_calls_encoder(encoder, prefix=\"\")\n",
    "decoder_hook, decoder_layers = hook_model(decoder, include_class_name=False)\n",
    "decoder_calls, decoder_layer_names = get_forward_calls_decoder(decoder, prefix=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d601bc68-41bd-43d0-92b7-08e328811b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Encoder and Decoder\n",
    "enc_layer_index = -1\n",
    "l_enc = encoder_layer_names[enc_layer_index]\n",
    "dec_layer_index = -1\n",
    "l_dec = decoder_layer_names[dec_layer_index]\n",
    "\n",
    "pre_enc, post_enc = split_model(encoder, l_enc, partial(get_forward_calls_encoder, prefix=\"\"))\n",
    "pre_dec, post_dec = split_model(decoder, l_dec, partial(get_forward_calls_decoder, prefix=\"\"))\n",
    "\n",
    "# Merge Encoder and Decoder\n",
    "pre = compose_funclist([\n",
    "    pre_enc,\n",
    "    # post_enc,\n",
    "    # lambda x: bottleneck(x)[1],\n",
    "    # pre_dec,\n",
    "    # post_dec,\n",
    "])\n",
    "\n",
    "post = compose_funclist([\n",
    "    # pre_enc,\n",
    "    post_enc,\n",
    "    lambda x: bottleneck(x)[1],\n",
    "    pre_dec,\n",
    "    post_dec,\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7d9e270-9ccc-4227-8ad6-00fb4eb38768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_std(features):\n",
    "    \"\"\"\n",
    "    :param features: shape of features -> [batch_size, c, T]\n",
    "    :return: features_mean, feature_s: shape of mean/std ->[batch_size, c, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size, c = features.size()[:2]\n",
    "    features_mean = features.mean(dim=-1, keepdim=True)\n",
    "    features_std = features.std(dim=-1, keepdim=True) + 1e-6\n",
    "    return features_mean, features_std\n",
    "\n",
    "def adain_style_fusion(content_features, style_features):\n",
    "    final_feature = content_features.clone()\n",
    "    content_mean, content_std = calc_mean_std(content_features)\n",
    "    style_mean, style_std = calc_mean_std(style_features)\n",
    "    fused_feature = style_std * (content_features - content_mean) / content_std + style_mean\n",
    "    \n",
    "    return fused_feature\n",
    "\n",
    "\n",
    "def get_gram_matrix(h, remove_mean=True):\n",
    "    b, c, T = h.shape\n",
    "    assert b == 1\n",
    "    f = h[0]\n",
    "    if remove_mean:\n",
    "        f = f - f.mean(dim=1, keepdim=True)\n",
    "    G = torch.matmul(f, f.permute(1, 0))\n",
    "    G = G / T\n",
    "    \n",
    "    return G\n",
    "\n",
    "def whitening_transform(h):\n",
    "    eps = 1e-10\n",
    "    b, c, T = h.shape\n",
    "    assert b == 1\n",
    "    \n",
    "    h = h.to(torch.double)\n",
    "    G = get_gram_matrix(h).to(torch.double)\n",
    "    \n",
    "    \n",
    "    E, D, V = torch.linalg.svd(G, full_matrices=True)\n",
    "    \n",
    "    i = len(D)\n",
    "    for j in range(len(D)):\n",
    "        if D[j] < eps:\n",
    "            i = j\n",
    "            break\n",
    "            \n",
    "    \n",
    "    Dt = D[:i]    \n",
    "    Dt = Dt ** (-0.5)\n",
    "    Dt = torch.diag(Dt)\n",
    "    D = torch.diag(D)\n",
    "    Et = E[:, :i]\n",
    "    Vt = V[:i, :]\n",
    "    A = Et @ Dt @ Et.T\n",
    "    \n",
    "    f = h.reshape(c, T)\n",
    "    f = f - f.mean(dim=1, keepdim=True)\n",
    "    wh = A @ f\n",
    "\n",
    "        \n",
    "    wh = wh.reshape(b, c, T)\n",
    "    return wh\n",
    "\n",
    "def coloring_transform(wh, h_style):\n",
    "    b, c, T = h_style.shape\n",
    "    assert b == 1\n",
    "        \n",
    "    h_style = h_style.to(torch.double)\n",
    "    G_style = get_gram_matrix(h_style).to(torch.double)\n",
    "    \n",
    "    E, D, V = torch.linalg.svd(G_style, full_matrices=True)\n",
    "\n",
    "    D = D ** (0.5)\n",
    "    D = torch.diag(D)\n",
    "    A = E @ D\n",
    "    A = A @ E.T\n",
    "    A = A\n",
    "    \n",
    "    b2, c2, T2 = wh.shape\n",
    "    wh = wh.reshape(c2, T2)\n",
    "    # wh = wh\n",
    "    sh = A @ wh\n",
    "    sh = sh + h_style.reshape(c, T).mean(dim=1, keepdim=True)\n",
    "    sh = sh.reshape(b2, c2, T2)\n",
    "    \n",
    "    return sh    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c9d7e7ba-fa76-4db3-9f05-0ba139a38ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_transfer(x_content, x_style, method='adain', output_file_name='tmp.mp3'):\n",
    "    assert method in ['adain', 'wct']\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h_content = pre(x_content)\n",
    "        h_style = pre(x_style)\n",
    "        \n",
    "        if method == 'wct':\n",
    "            h_fuse = whitening_transform(h_content)\n",
    "            h_fuse = coloring_transform(h_fuse, h_style).to(torch.float32)\n",
    "        elif method == 'adain':\n",
    "            h_fuse = adain_style_fusion(h_content, h_style)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        x_fuse_hat = post(h_fuse)\n",
    "        \n",
    "    audio = save(x_fuse_hat)\n",
    "    audio.write_audio_to_file(f\"out/style_transfer/{output_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e4f8c4b8-320d-4c01-b265-f8a0699cabad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wave wiles\n",
    "freq = 261.63\n",
    "\n",
    "sin_wav, _ = np.sin(2 * np.pi * freq * t), sample_rate\n",
    "piano_wav, _ = librosa.load('data/notes/piano-C4.wav', sr=sample_rate)\n",
    "violin_wav, _ = librosa.load('data/notes/violin-C4.wav', sr=sample_rate)\n",
    "flute_wav, _ = librosa.load('data/notes/flute-C4.wav', sr=sample_rate)\n",
    "trumpet_wav, _ = librosa.load('data/notes/trumpet-C4.wav', sr=sample_rate)\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_wave(wav):\n",
    "    wav = wav[:num_seconds * sample_rate]\n",
    "    x = torch.Tensor(wav).to(device)[None,None,:] / max(wav.max(), -wav.min())\n",
    "    return x\n",
    "\n",
    "sin_x = preprocess_wave(sin_wav)\n",
    "piano_x = preprocess_wave(piano_wav)\n",
    "violin_x = preprocess_wave(violin_wav)\n",
    "flute_x = preprocess_wave(flute_wav)\n",
    "trumpet_x = preprocess_wave(trumpet_wav)\n",
    "\n",
    "instruments = ['sin', 'piano', 'violin', 'flute', 'trumpet']\n",
    "xs = [sin_x, piano_x, violin_x, flute_x, trumpet_x]\n",
    "transfer_algorithms = ['adain', 'wct']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "129278f4-5f4d-444a-9d92-fed6404c709f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for method in transfer_algorithms:\n",
    "    for content_x, content_instrument in zip(xs, instruments):\n",
    "        audio = save(content_x)\n",
    "        audio.write_audio_to_file(f\"out/style_transfer/{content_instrument}.mp3\")\n",
    "        for style_x, style_instrument in zip(xs, instruments):\n",
    "            style_transfer(content_x, style_x, method=method, output_file_name=f\"{content_instrument}2{style_instrument} {method}.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75627bb5-82ef-4452-a76d-6099ebcbe1a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m bottleneck \u001b[38;5;241m=\u001b[39m vqvae\u001b[38;5;241m.\u001b[39mbottleneck\u001b[38;5;241m.\u001b[39mlevel_blocks[level]\n\u001b[1;32m     10\u001b[0m decoder \u001b[38;5;241m=\u001b[39m vqvae\u001b[38;5;241m.\u001b[39mdecoders[level]\n\u001b[0;32m---> 13\u001b[0m wave \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mchirp(t, \u001b[43mf_start\u001b[49m, num_seconds, f_end)\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39msignal\u001b[38;5;241m.\u001b[39mchirp(t, f_start, num_seconds, f_end)[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m     15\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(x)\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_start' is not defined"
     ]
    }
   ],
   "source": [
    "# import scipy\n",
    "# from lucent.optvis.render import hook_model\n",
    "# from functools import partial\n",
    "# from jukebox.utils.jukebox_utils import get_forward_calls_encoder, get_forward_calls_decoder, split_model\n",
    "\n",
    "# #x = torch.zeros(1,1,44100)\n",
    "# level = 2\n",
    "# encoder = vqvae.encoders[level]\n",
    "# bottleneck = vqvae.bottleneck.level_blocks[level]\n",
    "# decoder = vqvae.decoders[level]\n",
    "\n",
    "\n",
    "# wave = scipy.signal.chirp(t, f_start, num_seconds, f_end)\n",
    "# x = scipy.signal.chirp(t, f_start, num_seconds, f_end)[None, None, :]\n",
    "# x = torch.from_numpy(x).cuda().float()\n",
    "\n",
    "\n",
    "# hook, layers = hook_model(encoder, include_class_name=False)\n",
    "# print(list(layers.keys())[:10])\n",
    "# x_z = encoder(x)[-1]\n",
    "# encoder_calls, encoder_layer_names = get_forward_calls_encoder(encoder, prefix=\"\")\n",
    "\n",
    "# for l in encoder_layer_names:\n",
    "#     pre, post = split_model(encoder, l, partial(get_forward_calls_encoder, prefix=\"\"))\n",
    "#     try:\n",
    "#         h1 = hook(l)\n",
    "#         h2 = pre(x)\n",
    "#         print((h2 == h1).all().item())\n",
    "#         if not (h2 == h1).all().item():\n",
    "#             error = torch.abs(h1 - h2).mean()\n",
    "#             print(f\"Layer {l} failed with error = {error}\")\n",
    "#     except:\n",
    "#             continue\n",
    "      \n",
    "    \n",
    "# hook, layers = hook_model(decoder, include_class_name=False)\n",
    "# _, xs_quantized, _, _ = bottleneck(x_z)\n",
    "# decoder([xs_quantized], all_levels=False)\n",
    "# decoder_calls, decoder_layer_names = get_forward_calls_decoder(decoder, prefix=\"\")\n",
    "# # print(decoder)\n",
    "# for l in decoder_layer_names:\n",
    "#     pre, post = split_model(decoder, l, partial(get_forward_calls_decoder, prefix=\"\"))\n",
    "#     try:\n",
    "#         h1 = hook(l)\n",
    "#         h2 = pre(xs_quantized)\n",
    "#         print((h2 == h1).all().item())\n",
    "#         if not (h2 == h1).all().item():\n",
    "#             error = torch.abs(h1 - h2).mean()\n",
    "#             print(f\"Layer {l} failed with error = {error}\")\n",
    "        \n",
    "#     except:\n",
    "#         continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
